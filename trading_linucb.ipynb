{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contextual Bandit in TSMC Stock Trading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we present how to use striatum package to conduct contextual bandit experiments with application to the stock trading. We first import the required packages, including pandas, numpy, matplotlib, and striatum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from striatum.storage import (history, model, action)\n",
    "from striatum.bandit import LinUCB\n",
    "from striatum.storage.action import Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, import the data set. The data sets contains the closed price, weekly log return, and 14 trading information variables of TSMC stock. The data set is downloaded from the TEJ database.\n",
    "\n",
    "The training period starts from week 0 (2011/9/2) to week 204 (2015/8/14), totally 205 weeks. The testing period starts from week 205 (2015/8/17) to week 257 (2016/8/19), totally 53 weeks.\n",
    "\n",
    "Also, we apply the Z normalization on our context variables. Note that the normalization is based on the training period so that no future information is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_table('data4.csv', sep=',', encoding='cp950', index_col=0)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2,18):\n",
    "    mean = np.average(data.iloc[0:204, i])\n",
    "    std = np.std(data.iloc[0:204, i])\n",
    "    data.iloc[:, i] = (data.iloc[:, i] - mean) / std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is initializing the contextual bandit learner. Here we have two actios - 'long' and 'short'. The history_stroage object is used to store contexts, recommendations, and rewards histories. The model_storage is used to store parameters of the LinUCB learner.\n",
    "\n",
    "Here, our policy is LinUCB (Li et. al, 2010) with tunning parameter alpha = 0.4. Note that I haven't tried to tune the parameter. If you're interested, try to find the optimal alpha for this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action_storage = action.MemoryActionStorage()\n",
    "action_storage.add([Action(1, 'long'), Action(2, 'short')])\n",
    "\n",
    "history_storage = history.MemoryHistoryStorage()\n",
    "model_storage = model.MemoryModelStorage()\n",
    "policy = LinUCB(history_storage=history_storage,\n",
    "                model_storage=model_storage,\n",
    "                action_storage=action_storage,\n",
    "                context_dimension=14,\n",
    "                alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll squentially train the learner. We use the 14 trading information variables at time i as our context, and derive the recommended action to do at time i + 1, and update the reward of this action by the log return at time i + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(0, 257):\n",
    "    context = data.iloc[i, 2:16].tolist()\n",
    "    context = {1: context, 2: context}\n",
    "    history_id, recommendation = policy.get_action(context)\n",
    "    action_id = recommendation.action.id\n",
    "    if action_id == 1:\n",
    "        (history_id, {action_id: data.iloc[i + 1, 1]})\n",
    "        policy.reward(history_id, {action_id: data.iloc[i + 1, 1]})\n",
    "    elif action_id == 2:\n",
    "        policy.reward(history_id, {action_id: -1 * data.iloc[i + 1, 1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we extract the historical actions, scores, and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "last_history_id = policy.history_storage.n_histories\n",
    "rewards = np.zeros(last_history_id)\n",
    "actions = np.zeros(last_history_id)\n",
    "scores = np.zeros(last_history_id)\n",
    "for i in range(0, last_history_id):\n",
    "    rewards[i] = policy.history_storage.get_history(i).recommendations.reward\n",
    "    actions[i] = policy.history_storage.get_history(i).recommendations.action.id\n",
    "    scores[i] = policy.history_storage.get_history(i).recommendations.score\n",
    "\n",
    "actions = actions.astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The traiding strategy is:\n",
    "(1) Only try to change position when the log return of this week > 0.685%. If the reward is < 0.685%, do not change the position, and no transaction fee is required. \n",
    "(2) If the recommended action is the same as the current week, do not change the position.\n",
    "(3) When we need to change our position, the transaction fee is incurred. (Long: 0.585%, Short: 0.685%.)\n",
    "Now, we calculate the cumulative wealth of the LinUCB strategy for the testing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cum_wealth = np.zeros(53)\n",
    "current_position = actions[204]\n",
    "cum_wealth[0] = 121 * (1-0.00585)\n",
    "for i in range(0, 52):\n",
    "    if rewards[i + 204] > 0.00685:\n",
    "        if actions[i + 204] == 2 & actions[i + 205] == 1:\n",
    "            cum_wealth[i + 1] = cum_wealth[i] * (1 + rewards[i + 204] - 0.00685)\n",
    "            current_position = 1\n",
    "        elif actions[i + 204] == 1 & actions[i + 205] == 2:\n",
    "            cum_wealth[i + 1] = cum_wealth[i] * (1 + rewards[i + 204] - 0.00585)\n",
    "            current_position = 2\n",
    "        else:\n",
    "            cum_wealth[i + 1] = cum_wealth[i] * (1 + rewards[i + 204])\n",
    "            current_position = actions[i + 205]\n",
    "    else:\n",
    "        if  current_position == actions[i + 205]:\n",
    "            cum_wealth[i + 1] = cum_wealth[i] * (1 + rewards[i + 204])\n",
    "        else:\n",
    "            cum_wealth[i + 1] = cum_wealth[i] * (1 - rewards[i + 204])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compare the LinUCB strategy with the single buy-and-hold strategy. It outperforms the single strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(range(205, 258), cum_wealth, label=\"LinUCB Strategy\")\n",
    "plt.plot(range(205, 258), data.iloc[205:258, 0], label=\"Buy-and-hold\")\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=8)\n",
    "plt.legend(loc=\"upper left\", fancybox=True, fontsize= 12)\n",
    "plt.xlabel('Week', fontsize= 12)\n",
    "plt.ylabel('Cumulative Wealth', fontsize= 12)\n",
    "plt.title(\"Cumulative Wealth: 2015/08/17 - 2016/08/19\", fontsize= 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "returns = [(cum_wealth[i] - cum_wealth[i - 1]) / cum_wealth[i - 1] for i in range(1, 53)]\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.plot(range(206, 258), returns, label=\"LinUCB Strategy\")\n",
    "plt.plot(range(206, 258), data.iloc[205:257, 1], label=\"Buy-and-hold\")\n",
    "plt.tick_params(axis='both', which='major', labelsize=10)\n",
    "plt.tick_params(axis='both', which='minor', labelsize=8)\n",
    "plt.legend(loc=\"lower right\", fancybox=True, fontsize = 12)\n",
    "plt.xlabel('Week', fontsize = 12)\n",
    "plt.ylabel('Weekly Return', fontsize = 12)\n",
    "plt.title(\"Weekly Return: 2015/08/17 - 2016/08/19\", fontsize = 15)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
